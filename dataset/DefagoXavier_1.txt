
Title
The cost of probabilistic agreement in oblivious
robot networks

Issue Date 2010-05-16

Abstract
In this paper, we look at the time complexity of two agreement problems in networks of oblivious mobile
robots, namely, at the gathering and scattering problems. Given a set of robots with arbitrary initial locations and
no initial agreement on a global coordinate system, gathering requires that all robots reach the exact same but
not predetermined location. In contrast, scattering requires that no two robots share the same location. These
two abstractions are fundamental coordination problems in cooperative mobile robotics. Oblivious solutions are
appealing for self-stabilization since they are self-stabilizing at no extra cost. As neither gathering nor scattering
can be solved deterministically under arbitrary schedulers, probabilistic solutions have been proposed recently.
The contribution of this paper is twofold. First, we propose a detailed time complexity analysis of a modified
probabilistic gathering algorithm. Using Markov chains tools and additional assumptions on the environment,
we prove that the convergence time of gathering can be reduced from O(n2) (the best-known bound) to O(1) or
O(log n  log(log n)), depending on the model of multiplicity detection. Second, using the same technique, we
prove that scattering can also be achieved in fault-free systems with the same bounds.
1 Introduction
Many future applications of mobile robotics envision groups of mobile robots self-organizing and cooperating
toward the resolution of common objectives. In many cases, such groups of robots are aimed at being deployed in
adverse environments, such as in space, in deep sea, or after disasters (natural or not). Thus, a group must be able
to self-organize in the absence of any prior infrastructure (e.g., no global positioning), and ensure coordination in
spite of the presence of faulty elements among the robots, as well as other unanticipated environmental changes.
Suzuki and Yamashita [8] proposed a formal model to analyze and prove the correctness of agreement problems
in robot networks. In their model, robots are represented as points that evolve on a plane devoid of any
landmarks. At any given time, a robot can be either idle or active. When a robot becomes active, it observes
the locations of the other robots, computes a target position, and moves towards it. The time when a robot becomes
active is governed by an activation scheduler (or daemon). Between two activations robots forget their past
computations (robots are said to be oblivious). Interestingly, any algorithm proved correct in this model is also
inherently self-stabilizing.
The gathering problem, also known as the Rendezvous problem, is fundamental for coordination in oblivious
mobile robotics. Briefly, given a set of robots with arbitrary initial locations and no initial agreement on a global
coordinate system, gathering requires that all robots, following their algorithm, reach the exact same location.
That location, not agreed upon initially, must be reached within a finite number of cycles, with all robots remaining
there afterward. The dual problem of gathering is the scattering problem. Scattering requires that, starting from
an arbitrary configuration, eventually no two robots share the same position.
It turns out that neither deterministic gathering nor scattering are possible without additional assumptions.
Most of the work done so far in order to circumvent this impossibility focuses on the additional assumptions
1
the system needs. Surprisingly, the use of randomization has however drawn only little attention so far. No formal
framework was proposed in order to analyze the correctness and the complexity of probabilistic algorithms
designed for robots networks. In a companion paper [1], we investigated some of the fundamental limits of deterministic
and probabilistic gathering in the face of a wide range of synchrony and fault assumptions. Probabilistic
scattering was analyzed for the first time by Dieudonn¬¥e and Petit [2]. However, neither work proposed an actual
framework in which to analyze the complexity of proposed solutions.
In this paper, we advocate the use of Markov chains as a simple and efficient tool to analyze and compare
probabilistic strategies in oblivious robot networks. Note that, in oblivious robot networks, computations can
depend only on the current view of the robots, i.e., without making any reference to the past. This behavior makes
Markov chains an appealing tool for analyzing their correctness and complexity since, by definition, a Markov
chain models a system wherein the next configuration depends strictly on the current one. The only difficulty
with using Markov chains consists in associating an appropriate Markov chain to each probabilistic strategy. In
this work, we focus on the analysis of existing probabilistic strategies for scattering and gathering. We also claim
that our analysis can be easily applied to a broad class of probabilistic strategies (e.g., leader election, flocking,
constrained scattering, pattern formation).
Contribution. We show that the time complexity of probabilistic gathering in a fault-free environment can be
improved from O(n2) to as little as O(1) rounds1 when the algorithms rely on additional information related to
the environment (e.g., strong multiplicity knowledge). And, even when information on multiplicity is incomplete
(weak multiplicity), we still show a convergence of O(log n  log(log n)). We also show the exact same bounds
for the scattering problem.
Structure. The paper is structured as follows. Section 2 describes the robot network and system model. Section 3
formally defines the gathering and scattering problems. Section 4 presents the analysis framework. We then
analyze the convergence of gathering and scattering both under strong multiplicity (Sect. 5) and under weak
multiplicity (Sect. 6). Section 7 concludes the paper and discusses some open problems.
2 Model
We now present the system model considered throughout the paper. The model of robots, and most of the definitions,
are due to Suzuki and Yamashita [8] and Prencipe [6].
Robot networks. The system consists of a finite set of robots modeled as dimensionless points moving on a
two-dimensional plane. The robots have arbitrary initial locations. They are capable of sensing the environment,
computing a position, and moving toward a destination. When sensing, a robot can determine the position of other
robots relative to its own local coordinate system.
In this paper, robots are said to have unlimited visibility, in the sense that they are always able to sense the
position of all other robots, regardless of their proximity.
Multiplicity detection. When several robots share the same location, this location is called a point of multiplicity.
Robots are said to have strong multiplicity knowledge when they are aware of the number of robots located at
each point of multiplicity. In contrast, when robots have weak multiplicity knowledge, they know which points are
points of multiplicity, but are unable to count how many robots are located there.
Section 5 assumes strong multiplicity knowledge, while Section 6 assumes weak multiplicity.
System model. We consider the model first introduced by Suzuki and Yamashita [8], called SYm, in which
robots are repeatedly active and inactive. When a robot becomes active, it performs an atomic computational
cycle composed of the following three actions: observation, computation, and motion.
 Observation. An observation returns a snapshot of the positions of all robots.
 Computation. Using the observed environment, a robot executes its algorithm to compute a destination.
 Motion. The robot moves to this destination (by a non-zero distance but without always reaching it).
The model considers discrete time at irregular intervals. At each time, some subset of the robots become
active and complete an entire computation cycle. Robots can be active either simultaneously or sequentially. Two
1A round is the shortest fragment of execution where all robots are activated at least once.
2
robots that are active simultaneously observe the exact same environment (according to their respective coordinate
systems).
Moreover, robots are assumed to be oblivious (i.e., stateless), in the sense that a robot does not keep any
information between two different computational cycles.
The algorithm of robots is expressed with an I/O automaton [3, 4]. The local state of a robot at time t is the
state of its input/output variables and the state of its local variables and registers. A network of robots is modeled
by the parallel composition of the individual automaton of each robot. A configuration of the system at time t is
the union of the local states of the robots in the system at time t. An execution e = (c0; : : : ; ct; : : :) of the system
is an infinite sequence of configurations, where c0 is the initial configuration,2 and every transition ci ! ci+1 is
associated to the execution of a subset of the previously defined computational cycles.
Schedulers. A scheduler decides at each configuration the set of robots allowed to perform their actions. A
scheduler is said to be fair if, in an infinite execution, a robot is activated infinitely often. A scheduler is centralized,
if it ensures that at most one single robot is active at any given time, otherwise it is distributed.
3 Gathering and Scattering
A network of robots is in a legitimate configuration with respect to the requirements of gathering if all robots in
the system share the same position on the plane. Let us denote by PGathering this predicate. An algorithm solves
the gathering problem in an oblivious system if the following two properties are verified:
 Convergence. Any execution of the system starting in an arbitrary configuration reaches in a finite number
of cycles a configuration that satisfies PGathering.
 Closure. Any execution starting in a legitimate configuration with respect to PGathering contains only
legitimate configurations.
Gathering is difficult to achieve in most environments. Therefore, weaker forms of gathering have also been
studied. One interesting variant requires robots to converge asymptotically toward a single location, rather than
reach such a location in finite time. The convergence is however considerably easier to deal with. For instance,
with unlimited visibility, convergence can be achieved trivially by having robots move to the barycenter of the
network [8].
The scattering problem was first introduced by Suzuki and Yamashita [7]. The problem aims at arranging a set
of robots such that eventually no two robots share the same position. Let us denote by PScattering this predicate.
In the sequel, we rely on the following definition proposed by Dieudonn¬¥e and Petit [2]:
 Convergence. Any execution of the system starting in an arbitrary configuration reaches in a finite number
of cycles a configuration that satisfies PScattering.
 Closure. Any execution starting in a legitimate configuration with respect to PScattering contains only
legitimate configurations.
4 Analysis framework
In this section, we introduce further definitions needed to analyze the convergence time of probabilistic gathering
and scattering. A detailed description of these notions can be found in the literature [5].
Random variables We denote by Xn a random variable. For instance, in our case this could represent the
number of groups of size x after n cycles of the algorithm. We will study a discrete-time stochastic process, that
is, a sequence fXngn0 of random variables.
In the sequel, we use the following notation:
 P[Xn = x] is the probability of the event fXn = xg.
 E[Xn] is the expectation of Xn.
 X : k 7! P[X = k] denotes the probability distribution of a random variable X.
2Unless stated otherwise, we make no specific assumption regarding the respective positions of robots in initial configurations.
3
 P[A j B] is the conditional probability that reads: ‚Äúthe probability of A, given B‚Äù.
Markov chains Markov chains form a specific class of stochastic processes, with the following fundamental
property: the probabilistic dependence on the past is only related to the previous state.
Definition 1 Let (Xn)n2N be a discrete time stochastic process with countable state space E. A stochastic process
is called a Markov chain if, for all integers n  0 and all states i0; i1; : : : ; in??1; i; j, we have:
P[Xn+1 = j j Xn = i;Xn??1 = in??1; : : : ;X0 = i0] = P[Xn+1 = j j Xn = i]
In this paper, we advocate that Markov chains constitute a simple verification tool, well-adapted to the analysis
of distributed strategies in oblivious robot networks since, in such networks, the next move of a robot depends only
on its current position.
Asynchronous rounds and moving distance. An asynchronous round is defined as the shortest fragment of an
execution in which each process in the system executes its actions at least once. Throughout this paper, we adopt
the number of asynchronous rounds as the unit to evaluate the time complexity of algorithms, which is a standard
criterion for asynchronous distributed systems. Although the maximal distance that a robot can reach in a single
round is fixed by the model, note that the probability of two robots being at moving distance of each other does
not depend on the number of robots. So, in order to simplify the discussion for the gathering analysis, we build
our argument on the case where all robots are initially within moving distance of each other.
5 The Case of Strong Multiplicity Knowledge
In this section, we assume that robots have strong multiplicity knowledge.
To achieve scattering, we want robots located at the same point x0 to move randomly to different destinations.
If we are able to generate a sufficiently large number of ‚Äúpossible destinations‚Äù, it is more likely that the robots will
move to distinct locations. Therefore, to be efficient, it is desirable that the number of these ‚Äúpossible destinations‚Äù
increases according to the multiplicity of x0. Since robots have strong multiplicity knowledge, they are aware of
the number of robots located at each multiplicity point.
In gathering, we require all robots to gather at a single location. Since robots have strong multiplicity knowledge,
they are able to determine the best location to gather, i.e, the point of maximal multiplicity.
5.1 Probabilistic scattering
Dieudonn¬¥e and Petit [2] proved that deterministic scattering is impossible in the SYm model without additional
assumptions, and proposed an original probabilistic solution based on the use of Voronoi diagrams, described and
analysed in Section 6.1.
Definition 2 Let P = fp1; p2; : : : ; png be a set of points in the Cartesian 2-dimensional plane. The Voronoi
diagram of P is a subdivision of the plane into n cells, one for each point in P. The cells have the property
that an arbitrary point q belongs to the Voronoi cell of point pi if and only if, for any other point pj 2 P,
dist(q; pi) < dist(q; pj) where dist(p; q) is the Euclidean distance between p and q. In particular, the strict
inequality means that points located on the boundary of the Voronoi diagram belong to no Voronoi cell.
In this section, we modify the scattering algorithm of [2] in order to improve the complexity. The idea of
our algorithm referred in the following Algorithm 5.1 is as follows. Robots choose uniformly at random a point
within 2n2 different positions in their Voronoi cell. Note that Algorithm 5.1 uses implicitly the strong multiplicity
knowledge in the computation of the set of possible choice positions, i.e. n. If we assume n known or the
knowledge of an upper bound of n then Algorithm 5.1 works under a weak multiplicity model.
Theorem 1 The expected convergence time of Algorithm 5.1 is O(1).
Proof: Let [t0; t1] be the shortest fragment in which each robot is activated at least once. Let P = fp1; p2;    ; pwg
be the set of points occupied by two or more robots at t0, where w = jPj. We define the indicator random variable
Zi as follows: Zi = 1 if all robots located at the same point pi are located on different points at time t1, and
4
Algorithm 5.1 Probabilistic Scattering executed by robot ri with strong multiplicity knowledge.
Compute the Voronoi diagram;
Cell i := Voronoi cell where ri is located;
Current Pos := position where ri is located;
Let Pos be a set of 2n2 positions in Cell i:
Move toward a position in Pos chosen uniformly at random,
Zi = 0 otherwise. Notice thatfZ1;Z2;    g are mutually independent because we use Voronoi diagrams and thus
any two robots from different points never reach the same position.
Let mi be the multiplicity of pi at t0. To prove the theorem, we show that the probability P[
Vw
i=1 Zi = 1] is
bounded by a constant. Since two robots moving at different time necessarily have different destinations, the worst
case scenario is when mi robots are activated simultaneously during the interval [t0; t1]. Thus, the probability
P[Zi = 1] is bounded as follows:
P[Zi = 1] 

2n2 ?? 1
2n2

2n2 ?? 2
2n2

  

2n2 ?? mi
2n2



1 ??
mi
2n2
mi


1 ??
m2i
2n2

The random variables being independent, we get:
P[
w^
i=1
Zi = 1] 
Yw
i=1

1 ??
m2i
2n2


Yw
i=1

1 ??
mi
2n

Therefore, we can write :
log(P[
w^
i=1
Zi = 1]) 
Xw
i=1
log

1 ??
mi
2n

 ??
Xw
i=1
mi
2n
The fact that
Pw
i=1mi  n leads to :
P[
w^
i=1
Zi = 1]  exp
 
??
Xw
i=1
mi
2n
!
 exp

??
1
2

The theorem follows.
5.2 Probabilistic Gathering
In this section, we analyze the complexity of probabilistic gathering in a fault-free environment. The algorithm
presented in this section extends one analyzed in earlier work [1].
We prove that additional information on the environment can significantly improve the convergence time of
gathering. Using strong multiplicity knowledge, for example, we obtain a tighter bound of O(1) which significantly
improves the best known bound of O(n2).
In earlier work [1], we proposed a probabilistic algorithm that solves the fault-free gathering in the SYm
model, under a specific class of schedulers, known as k-bounded schedulers.3
Briefly, the algorithm works as follows. A robot, when chosen by the scheduler, randomly selects one of its
neighbors and moves towards its position with probability 1
 „É£        ‚Äô „Éß „Éé  
„É£    „É£        „Éß
„É©       „Ç§„É•   „É¢„É´     
   „Ç§   „Éß „É©       „É•  „Ç£  „Ç¶„Ç•„É£ 
  „É•            „Ç§
  „Éß
„Ç¶„Éé „É£  „É•     „É£        „É£      
  „Éß
„Ç™
„É©        „Éû„Ç£„Ç§„Ç•     „Éû„Ç£„Ç¢„Ç•     
„Éß „Éé               „Éß
„ÉÑ„É£    „Ç£„ÉÅ „Ç™„Éß„Ç§„Ç•      „Éß „Éé    
„É£                „Éß
„É©    „É£            „Ç¢
„Ç§„Éß „Éé  „É£  
            „É£    „Éß
„ÉÅ „Ç™„Éß„Ç§ „Éü         „Éß
„Éã„Ç≥   „Ç≥„Ç≥        
  „Ç≥„Ç≥        
  „Ç≥„Ç≥        
„Ç£„Éß„Éß„É£               „Ç•„Çµ
„ÉÅ„Ç≥ „Éõ „Çπ  „Ç£„Ç•„Çµ
   „Ç£„Éõ„Ç• „Çª „Ç¢ 
  „Ç¢
„Ç§
          „Ç£„Éõ„Ç•  „Ç£„Ç•„Çµ
  „Çµ
  „Ç¢ „ÇΩ„ÇΩ „Ç¢
„Ç§
  „Çµ
   „Ç£„Éõ„Ç• „Çπ „Ç¢ 
        „Ç£„Éõ„Ç•„Çµ
  „Çµ
„ÉÅ   „É£ „ÉÅ „Ç™„Éß„Ç§   „Éû„Ç£„Ç¢„Ç•   „Éß „Éé„É£   
 „ÇΩ           „ÇΩ    
     „Éß
„Éï „Ç¢ „Éå          „É£     
           „Ç¢
„Ç§„Éß
„Éü„Ç≥ „É§       „ÉÅ „Ç™„Éß„Ç§„Éß „ÉÑ„É£       
„É£       „Ç¢
„Ç§         
  „Éß „É§ ‚Äô     „Éß
„É©       „Éß
„É§ „Ç§ „ÉÅ „Ç™„Éß„Ç§    „Éû„Ç£„Ç¢„Ç•    „Éß
„Éü„Ç≥ „É§       „Éß „Éã„É£        
    „Éß „É¢„É£          „Éß
„É§    „É£      „Éß
„ÉÜ    „É£   „Éº„É£          „Éß „É©
                    
„Éß „ÉÅ  „Éï „Ç¢„É£            „Éß
„Éï   „É≠„Éº„Çµ „Éº „Ç© „É≥          „Éß „Éã  „Ç£„Éº    „Ç•„É£
         „Éº „Ç©„Éß „É©  „É™        „Éº „Ç©„É™
     „Éº       „Éß „É©   „É´    
           „É≠„Éº„Çµ „Éº „Ç©  „ÇΩ„ÇΩ „Ç¢„É≥ „Ç£    „É£ 
„Éü„É≠„É´„Ç¢ „Çπ „Ç¢„É≥ „Çπ „Ç¢„Ç•„Éß „É§„É£      
„Éü„É≠„É™ „Çπ  „Çõ „É´ „Çπ „Ç¢„É≥ „Çπ


„Ç¢

„Ç¢ „ÇΩ„ÇΩ
„Ç¢
„Ç§
„ÇΩ„ÇΩ„Ç¢ 
„Ç¢
„Ç§


„É´„ÇΩ„ÇΩ„Ç¢
„Çπ„Ç¢

„Ç¢ „ÇΩ„ÇΩ
„Ç¢
„Ç§

„Çπ


„Ç¢

„Ç¢ „ÇΩ„ÇΩ
„Ç¢
„Ç§
„ÇΩ„ÇΩ„Ç¢ 
„Ç¢
„Ç§



„Ç¢ „ÇΩ„ÇΩ
„Ç¢
„Ç§
„Éü„ÇΩ„ÇΩ„Ç¢
„Çπ„Ç¢ 


„Ç¢ „ÇΩ„ÇΩ
 „ÇΩ„ÇΩ „Ç¢
„Ç§
 
„Ç§


 
„Ç¢ „ÇΩ„ÇΩ
„Éü„ÇΩ„ÇΩ„Ç¢
„Çπ„Ç¢ 
„Ç§
„ÄÇ


„ÇØ
„Ç´
„É©        
„Éü„ÇΩ„ÇΩ„Ç¢
„Çπ„Ç¢  „Ç∑  „Ç£          „ÇΩ„ÇΩ„Ç¢„Ç£„Ç∑ „Ç•„Ç•„Éß
„É§           „Éü„É≠„É™ „Çπ „É≥  „Ç≥ „Éü„É≠„É™ „Çπ „É≥  „Éü„É≠„É™ „Çπ
 „Çõ „É´ „Çπ „Ç¢„É≥  
„ÇØ„Éß „É§„É£               
    „Éº „Ç© „Ç≥
„Éü„É≠„É™  „É≥ 
„É™
„Çπ„Ç¢

„ÇØ

„Ç¢
„ÇØ
„ÉÜ„É£              
„Ç£  „Ç¢
„ÇØ „Ç•    „Éß „Éõ„É£     „É• „Ç≥
 Zt = 1 when ‚Äúthere is only one maximal multiplicity point at time t.‚Äù
 Zt = 0 when ‚Äúthere are several maximal multiplicity points at time t.‚Äù
(Zt)t2N is a Markov chain and we need the expectation of the time needed for this stochastic process to reach
state 1 starting from state 0. Formally,
T1
0 = E[minft such that Zt = 1 knowing Z0 = 0g]
We obtain T1
0 = 8. This is enough to prove that a unique point of maximal multiplicity can be created in O(1)
expected rounds. Indeed, this stems from T1
0 = 8 and the fact that as soon as a unique point is created, any
activated robot will join it. This also gives that the gathering is achieved in a contant number of rounds.
6 The Case ofWeak Multiplicity Knowledge
In this section, we assume that robots have weak multiplicity knowledge. The algorithms proposed in Sect. 5, based
heavily on strong multiplicity knowledge, do not work under weak multiplicity. For the scattering algorithm the
multiplicity knowledge is implicitly used in the computation of the number of directions while for the gathering
algorithm uses explicitly in the code the strong multiplicity knowledge.
In this section we analyse Algorithm 6.1 (originally presented in [2]) that achieves scattering in a polylogarithmic
convergence time with weak multiplicity. For gathering, since it is now impossible for robots to distinguish
which point is the point of maximal multiplicity, we instead rely on scattering as an initial step.
6.1 Probabilistic scattering
The algorithm works as follows (Algorithm 6.1). Each robot uses a function Random() that returns a value
probabilistically chosen in the set f0; 1g: 0 with probability 3
4 , and 1 with probability 1
4 . When a robot ri becomes
active at time t, it first computes the Voronoi diagram of the set of points occupied by the robots. Then, ri moves
toward an arbitrary location inside its Voronoi cell Cell i if Random() returns 0. We now look at the convergence
time of Algorithm 6.1.
Algorithm 6.1 Probabilistic Scattering executed by robot ri with weak multiplicity knowledge.
Compute the Voronoi diagram;
Cell i := Voronoi cell where ri is located;
Current Pos := position where ri is located;
if Random() = 0 then
Move toward an arbitrary position in Cell i, different from Current Pos;
else Do not move;
Lemma 2 Let a period [t0; t1] be the shortest fragment in which all robots are activated at least once and execute
Algorithm 6.1. We define R as the set of robots located on a multiplicity point x0 at time t0, and Q as the set of
points on which at least one robot of R stays at time t1. Then, with probability at least 1??3e??jRj
11 , all points in Q
have multiplicity less than 3
4 jRj.
7
Proof: We define the random variable Z as the maximal multiplicity of all points in Q. Therefore, we want to
show that P[Z  3
4 jRj]  3
e
jRj
11
. To do so, we introduce the following two random variables:
 Z1 is ‚Äúthe multiplicity of point x0 at time t1‚Äù
 Z2 is ‚Äúthe maximal multiplicity of all points in Q n fx0g at time t1‚Äù
The reader may easily observe that P[Z1  3
4 jRj ^ Z2  3
4 jRj] = 0. Thus, we have
P[Z  3
4 jRj] = P[Z1  3
4 jRj _ Z2  3
4 jRj] = P[Z1  3
4 jRj] + P[Z2  3
4 jRj]
We now study P[Z1  3
4 jRj] and P[Z2  3
4 jRj] separately.
Case 1 P[Z1  3
4 jRj]  e??jRj
8
Since no point occupied by some robot can become the destination of another robot, no robot moves to x0
during [t0; t1]. Thus, if Z1  3
4 jRj holds, at most 3
4 jRj robots in R keep their position during [t0; t1]. From
the fact that each robot is activated at least once during that period, the probability that some robot on x0 at
t0 remains on x0 at t1 is at most 1
2 . Thus, using the random variable BjRj;12
following binomial distribution
with parameter jRj and 1
2 ,4 we obtain the upper bound for P[Z1  3
4 jRj]:
P[Z1  3
4 jRj]  P[BjRj;12
 3
4 jRj]  e??jRj
8
where we use Chernoff‚Äôs bound5 for the binomial distribution BjRj;12
. This proves the case.
Case 2 P[Z2  3
4 jRj]  2e?? 3
32 jRj
To have a point x 2 Q n fx0g with multiplicity higher than 3
4 jRj at t1, at least 3
4 jRj robots must leave x0
by time t1. In addition, those robots must leave x0 simultaneously because two robots in R leaving x0 at
different times necessarily have distinct destinations. Thus, there exists a time when more than 3
4 jRj robots
at the same position are activated (if such time does not exist during [t0; t1], clearly P[Z2  3
4 jRj] = 0).
Let t0 be the first time after t0 when at least 3
4 jRj robots on x0 are activated. We define y to be the
number of robots on x0 activated at t0, and Y to be the random variable representing the number of robots
leaving x0 at t0. Notice that if the event of 3
4 jRj  Y  1
4 jRj occurs, the multiplicity of any point in Q
becomes less than 3
4 jRj, and thus there is no chance that more than 3
4 jRj robots located at the same point
are simultaneously activated after t0, that is, P[

Z2  3
4 jRj j
	
j
3
4 jRj  Y  1
4 jRj
	
] = 0. Thus, it results
that P[Z2  3
4 jRj]  P[
3
4 jRj  Y
	
_
1
4 jRj  Y
	
] holds. Since Y is equivalent to the binomial random
variable By; 1
2
, using the same method as in the previous case, we obtain the following bound, which proves
the case:
P[Z2  3
4 jRj]  P[

3
4 jRj  Y

_

1
4 jRj  Y

]
 (P[By; 1
2

3
4 jRj] + P[By; 1
2

1
4 jRj])  2e??y8
 2e?? 3
32 jRj
Consequently, we obtain P[Z  3
4 jRj]  e??jRj
8 + 2e?? 3
32 jRj  3e??jRj
11 .
Lemma 3 Let a time interval [t0; t1] be a period containing k rounds, and let m be the maximal multiplicity at
time t0. Then, the maximal multiplicity at time t1 is less than 3m
4 with probability (1 ?? 4n
me
km
11
).
Proof: Let P = fp1; p2;    ; pwg be the set of points occupied by more than 3m
4 robots at t0, where w = jPj. We
define the indicator random variable Zi such that Zi = 1 if pi is divided into two or more points with multiplicity
less than 3m
4 , and Zi = 0 otherwise. Again, thanks to Voronoi diagrams, fZ1;Z2;    g are mutually independent.
4That is, the probability distribution of Bl;q is defined as P[Bl;q = k] =
??k
l

qk(1 ?? q)l??k for any k(0  k  l).
5For any  „Çª „Éº„Çµ „Éü„É≠„ÉÑ„Çµ  „Ç£„Ç¢ „Ç© „Ç•„É≥  „ÇΩ„ÇΩ„Ç§„Éß
„ÇØ
„Éã „Éï „Ç§„É£           „É©     „Ç¶
„Ç® 
„Ç≥
„Éü
„Äå
„Çõ
„Çπ„Ç¢
„Ç£„É¨ „Çπ „Ç¢„Ç•
„Äç
„Çπ
„É´
„Çπ„Ç¢
„Éü„É≠„É¨ „Çπ „Ç¢„É≥  „Ç£„Ç¢ „ÇΩ„ÇΩ „Ç¶„ÇΩ„ÇΩ
„Ç¢„Ç¢ „Ç•
 „Ç£„Ç¢ „ÇΩ„ÇΩ „Ç¶„ÇΩ„ÇΩ
„Ç¢„Ç¢ „Ç• 

„Ç¢ „ÇΩ„ÇΩ
„Ç®

„Ç¢„Ç¢

        „Ç¶
„Ç®  „Éß „É§   „Éß
„É©   „Éï „Ç¶    „Éß
„ÉÜ „Ç¢ „É§       „Ç¢„Ç¢  „Ç®  „Éû„Ç£ „Ç•   „Éß
„ÉÜ „Ç§ „É¢       „Ç¢„Ç¢  „Ç®  „É£    
 „Éû„Ç£  „Ç£ „Ç•„Ç•   „Éß
„É§     „Éï „Ç¶   „Çπ „Ç¢      „Çª „Ç¢„Ç¢  „Ç®„É£    
      „Çπ „Ç¢„Ç¢  „Ç®    „Ç¢„Ç¢  „Ç®„Éß „ÉÑ   „É£   
  „ÉÅ „Ç´„Éß„Ç¢„Éß
„É§ „Ç¶ „É§    „ÉÅ „Ç´„Éß„Ç¢  „Éû„Ç£  „Ç£ „Ç•„Ç•„Éß
„Ç´„Éß„Ç§ „Éü 
„É©           „Éß „ÉÅ „Ç´„Éß„Ç§„É£ 
       „É¢ „Ç™„Éß„Ç§   „É£       
„Ç£„ÉÅ „Ç´„Éß„Ç¢„Ç•    „Éß
„ÉÅ „Ç´„Éß„Ç§ „Éü         „Éß
„ÉÅ„Ç≥ „Éõ „Çπ  „Ç£„Ç•„Çµ
 „Éõ       
„Éä „ÉÅ „Ç´„Éß„Ç¢„Çµ
  „Éõ       
„Éò  „Çµ

        „Éõ„Çµ
„É©  „Ç¢
„Ç§
  „Çµ
„É©  „Ç¢ „ÇΩ„ÇΩ „Ç¢
„Ç§
  „Çµ
„Éï „Ç® „É¢    „É£         
     „Éß
„É§       „É§ „Ç§„Éß
„É¢     „Éû„Ç£  „Ç£ „Ç•„Ç•   „É£     
         „Éû„Ç£  „Ç£ „Ç•„Ç• „É£    
„Éß „É§„É£     „ÉÅ „Ç´„Éß„Ç§  „Éß
„É§ „Ç® „É§    „ÉÅ „Ç´„Éß„Ç§  „Éû„Ç£  „Ç£ „Ç•„Ç•„Éß
„Ç±
„Ç≠ „ÉÜ  „Éà
„É§      „Éß „Éã„É£         
  „Ç£  „Ç•„Éß „É¢„É£  „Éò    
„É£             „Éû„Ç£„Ç§„Ç• „Ç£ „É• 
 „Ç•  „Éû„Ç£„Ç¢„Ç•  „Éû„Ç£   „Ç£ „Ç•„Ç•„É£      „Éß „É©     
    „É£          „Ç£ 
        „Ç•„Éß
„Éû         „Éò        
„Éß „É§„É£              „É£ 
„É£    „Éß
„ÉÅ
„É©                 
       „Éß „É§      „É°¬¥
„ÇΩ„Éé„É•„É•„Éã „Ç£„Éè „ÉÜ„Ç•„É£  „Éò„Éä„É™„É§ „Éå„É•„É•„ÉÅ  „É´ „É¢ „Ç£„ÉÅ„Ç• „Éõ„Éß „Ç¢„ÇØ„Ç´„ÇØ„Éº„Éº„Éº„Ç≠ „Ç£„É™ „Éà¬¥„Ç•„É£
   „É§ „ÉÅ „Éã „Ç£„É§ „Éé„Ç•„Éß
„É°
„É≠„Ç¢„É≥ „É™ „Éà¬¥„É£ „Éò „Éå„É£ „É¢¬¥ „Éò„É£  „Éü „É° „Éü¬¥„Éß „Éã„É•  
  „Éß „Éé „É¢ „Éà„É£ „É£ „Éà„Éé„É¢„ÉÜ„É£  „Ç®„Ç´„ÇΩ„Ç´„Éº„Éß „É¢„É£ „Ç§„Éº„Éº„Ç´„Éß
„É≠„Ç§„É≥ „É´ „Éà¬¥  „Éã „Éü„Éß „É°   „Ç£   „Ç•„Éß „Éé „Éã„É¶„Éõ„É£  „Ç¢„Éº„ÇØ„ÇΩ„Ç¢„Ç¢„Ç±„É£ „Ç§„Éº„Éº„Ç≠„Éß
„É≠„Ç¶„É≥ „Éõ„Éß „ÉÅ„Éß „Éï„Éß „Éà „ÉÅ„Éß „Éò „Éí„É£ „É¢ „Éã„É£ „ÉÜ„ÉÅ„É£ „É¶„É¢„ÉÅ„É£ „Ç¢„Ç±„Ç±„Ç´„Éß
„É≠„Ç®„É≥ „Éõ„Éß „ÉÅ„Éß „Éï„É£ „É°„Éß „É¢„É£  „Éã„Éß „É©„Éß „É®„Éß „Éç „Éé„ÉÉ„Éû „Éß „Éé  „ÉÜ„É£
„Ç¢„ÇØ„Ç™„Ç£„Ç¢„Ç•„Ç≥„Ç¢„Éº„Ç™„ÇΩ„Ç¢„Ç™„Ç≠„É£ „ÉÅ „Ç§„Éº„Éº„Ç¶„Éß
„É≠„Ç™„É≥ „Éè„Éß„É°„Éß „Éõ„Éß „Éò „ÉÜ„Éß „ÉÜ „É¶ „Éü„É£ „Ç¢„Ç±„Ç±„Ç≠„Éß
„É≠„Ç´„É≥ „Éå„Éß „Éü„Éß „ÉÜ„Éû„É°„Éà„ÉÅ„Ç≥ „Éà        „Éß „Éé „Éü„Éß „Ç® „Éä
„É° „É¢  „ÉÅ  „Éà „É¢ „Ç£„Éä„É°„É¢„ÉÅ„Éà„É¢‚Äô„Éº„Ç¢„Ç•„É£  „Ç¢„ÇØ„Ç™„ÇΩ„Ç¢„Ç±„Éº„É£ „Éò „Ç§„Éº„Éº„Ç¢„Éß
„É≠„Ç≠„É≥ „Éé„Éß „É¢  „Éò„Éß „É´„Éß „ÉÅ         
„Éß „É§ „É£ „É© „É¶„Éß „Éò„É£ „Éà„Éß  „Éä„Éä„ÉÜ„É¢„É£ „Ç¢„Ç±„Ç±„Ç®„Éß
„É≠„ÇØ„É≥ „Éé„Éß „É¢  „Éò„Éß „É´„Éß „Éà   „Ç≥ „Éã   „Éß „É¢„Éé„ÉÅ„Éò
„Éè  „ÉÜ„É£ „Ç§„ÇØ„Ç£„Ç®„Ç•„Ç≥„Ç¢„Ç¶„Ç®„Ç≠„ÇΩ„Ç¢„Ç¶„Ç´„Ç¶„É£ „Ç¢„Ç±„Ç±„Ç±„Éß
„Ç¢„Éº